# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aOt9CRonp7QMS4ekEucePpOVlGGBWOWL
"""

# -*- coding: utf-8 -*-
"""
Diabetes ML Analysis - Fixed Streamlit Application
"""

import streamlit as st
import numpy as np
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import time
from collections import Counter

# Configure page
st.set_page_config(
    page_title="An√°lisis de Diabetes - ML Pipeline",
    page_icon="ü©∫",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Import ML libraries with error handling
@st.cache_resource
def import_ml_libraries():
    libraries = {}

    try:
        from sklearn.preprocessing import StandardScaler, LabelEncoder
        from sklearn.preprocessing import label_binarize
        from sklearn.impute import SimpleImputer
        from sklearn.compose import ColumnTransformer
        from sklearn.decomposition import PCA
        from sklearn.feature_selection import chi2, f_classif, SelectKBest, RFECV
        from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, HistGradientBoostingClassifier
        from sklearn.linear_model import LogisticRegression
        from sklearn.svm import SVC
        from sklearn.model_selection import train_test_split, RandomizedSearchCV
        from sklearn.metrics import (
            classification_report, confusion_matrix, roc_curve, auc,
            accuracy_score, f1_score
        )
        from sklearn.pipeline import Pipeline
        from scipy.stats import randint, uniform

        libraries.update({
            'StandardScaler': StandardScaler,
            'LabelEncoder': LabelEncoder,
            'label_binarize': label_binarize,
            'SimpleImputer': SimpleImputer,
            'ColumnTransformer': ColumnTransformer,
            'PCA': PCA,
            'chi2': chi2,
            'f_classif': f_classif,
            'SelectKBest': SelectKBest,
            'RFECV': RFECV,
            'RandomForestClassifier': RandomForestClassifier,
            'ExtraTreesClassifier': ExtraTreesClassifier,
            'HistGradientBoostingClassifier': HistGradientBoostingClassifier,
            'LogisticRegression': LogisticRegression,
            'SVC': SVC,
            'train_test_split': train_test_split,
            'RandomizedSearchCV': RandomizedSearchCV,
            'classification_report': classification_report,
            'confusion_matrix': confusion_matrix,
            'roc_curve': roc_curve,
            'auc': auc,
            'accuracy_score': accuracy_score,
            'f1_score': f1_score,
            'Pipeline': Pipeline,
            'randint': randint,
            'uniform': uniform,
            'SKLEARN_AVAILABLE': True
        })
    except ImportError as e:
        libraries['SKLEARN_AVAILABLE'] = False
        libraries['error'] = str(e)

    # Try to import UCI repo
    try:
        from ucimlrepo import fetch_ucirepo
        libraries['fetch_ucirepo'] = fetch_ucirepo
        libraries['UCI_AVAILABLE'] = True
    except ImportError:
        libraries['UCI_AVAILABLE'] = False
        libraries['fetch_ucirepo'] = None

    # Try to import imbalanced-learn
    try:
        from imblearn.over_sampling import ADASYN, SMOTE
        libraries['ADASYN'] = ADASYN
        libraries['SMOTE'] = SMOTE
        libraries['IMBALANCED_AVAILABLE'] = True
    except ImportError:
        libraries['IMBALANCED_AVAILABLE'] = False

    return libraries

def get_ml_libs():
    """Lazy loading of ML libraries with error handling"""
    if 'ml_libs' in st.session_state:
        return st.session_state['ml_libs']

    try:
        libs = import_ml_libraries()
        if not libs.get('SKLEARN_AVAILABLE', False):
            st.error("‚ö†Ô∏è Scikit-learn no est√° disponible. Instala las dependencias necesarias.")
            return None
        st.session_state['ml_libs'] = libs
        return libs
    except Exception as e:
        st.error(f"Error cargando librer√≠as ML: {str(e)}")
        return None

# Global configuration
RANDOM_STATE = 42
np.random.seed(RANDOM_STATE)

# Custom CSS
st.markdown("""
<style>
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 5px solid #ff6b6b;
    }
    .success-card {
        background-color: #d4edda;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 5px solid #28a745;
    }
    .warning-card {
        background-color: #fff3cd;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 5px solid #ffc107;
    }
    .error-card {
        background-color: #f8d7da;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 5px solid #dc3545;
    }
</style>
""", unsafe_allow_html=True)

def plot_confusion_matrix(cm, labels):
    """Plot confusion matrix using Plotly"""
    fig = go.Figure(data=go.Heatmap(
        z=cm,
        x=labels,
        y=labels,
        colorscale='Blues',
        showscale=True,
        text=cm,
        texttemplate="%{text}",
        textfont={"size": 16}
    ))

    fig.update_layout(
        title="Matriz de Confusi√≥n",
        xaxis_title="Predicci√≥n",
        yaxis_title="Real",
        width=500,
        height=500
    )

    return fig

@st.cache_data
def load_diabetes_data():
    """Load diabetes dataset"""
    ml_libs = get_ml_libs()
    if not ml_libs or not ml_libs.get('UCI_AVAILABLE', False):
        return None, None

    try:
        dataset = ml_libs['fetch_ucirepo'](id=296)
        X_raw = dataset.data.features.copy()
        y_raw = dataset.data.targets.copy()

        # Random sample for demo
        if len(X_raw) > 20000:
            sample_indices = np.random.choice(X_raw.index, size=20000, replace=False)
            X_raw = X_raw.loc[sample_indices].copy()
            y_raw = y_raw.loc[sample_indices].copy()

        return X_raw, y_raw
    except Exception as e:
        st.error(f"Error loading UCI data: {str(e)}")
        return None, None

def section_data_loading():
    """Data loading and exploration section"""
    st.header("üìä Carga y Exploraci√≥n de Datos")

    ml_libs = get_ml_libs()
    if ml_libs is None:
        st.error("No se pudieron cargar las librer√≠as de ML. Instala scikit-learn y dependencias.")
        return

    col1, col2 = st.columns([2, 1])

    with col1:
        st.subheader("Obtener datos")

        # UCI Dataset option
        uci_disabled = not ml_libs.get('UCI_AVAILABLE', False)
        if uci_disabled:
            st.info("‚ÑπÔ∏è El dataset UCI no est√° disponible. Usa la carga de CSV.")

        if st.button("üìÑ Cargar Diabetes desde UCI", type="primary", disabled=uci_disabled):
            with st.spinner("Cargando datos desde UCI..."):
                X_raw, y_raw = load_diabetes_data()
                if X_raw is not None and y_raw is not None:
                    st.session_state['X_raw'] = X_raw
                    st.session_state['y_raw'] = y_raw
                    st.success("‚úÖ Datos UCI cargados correctamente.")
                else:
                    st.error("Error cargando datos UCI. Usa la opci√≥n de CSV.")

        st.markdown("---")
        st.subheader("Subir archivo CSV")
        uploaded_file = st.file_uploader("Carga un CSV", type=["csv"])

        if uploaded_file is not None:
            try:
                df = pd.read_csv(uploaded_file)
                if df.empty:
                    st.error("El archivo est√° vac√≠o.")
                else:
                    st.dataframe(df.head())
                    target_col = st.selectbox(
                        "Selecciona la columna objetivo:",
                        options=df.columns.tolist(),
                        index=len(df.columns)-1
                    )

                    if st.button("Usar este dataset"):
                        X_raw = df.drop(columns=[target_col]).copy()
                        y_raw = df[[target_col]].copy()
                        st.session_state['X_raw'] = X_raw
                        st.session_state['y_raw'] = y_raw
                        st.success("‚úÖ Datos del CSV cargados.")
            except Exception as e:
                st.error(f"Error leyendo CSV: {e}")

    with col2:
        st.subheader("‚ÑπÔ∏è Instrucciones")
        st.markdown("""
        - Carga el dataset de diabetes UCI o sube tu CSV
        - La columna objetivo debe ser categ√≥rica
        - Contin√∫a con Preprocesamiento tras cargar datos
        """)

    # Show data exploration if data is loaded
    if 'X_raw' in st.session_state and 'y_raw' in st.session_state:
        show_data_exploration()

def show_data_exploration():
    """Show data exploration"""
    X_raw = st.session_state['X_raw']
    y_raw = st.session_state['y_raw']

    st.subheader("Exploraci√≥n r√°pida")

    tab1, tab2, tab3, tab4 = st.tabs([
        "üìã Vista General", "üî¢ Tipos de Datos",
        "üéØ Variable Objetivo", "üìä Valores Faltantes"
    ])

    with tab1:
        st.subheader("Primeras filas")
        st.dataframe(X_raw.head(10))
        st.subheader("Estad√≠sticas descriptivas")
        st.dataframe(X_raw.describe())

    with tab2:
        col1, col2 = st.columns(2)

        with col1:
            numeric_cols = X_raw.select_dtypes(include=[np.number]).columns.tolist()
            st.markdown(f"""
            <div class="success-card">
                <h4>üî¢ Variables Num√©ricas ({len(numeric_cols)})</h4>
                <p>{', '.join(numeric_cols[:5])}{'...' if len(numeric_cols) > 5 else ''}</p>
            </div>
            """, unsafe_allow_html=True)

        with col2:
            cat_cols = X_raw.select_dtypes(include=['object', 'category']).columns.tolist()
            st.markdown(f"""
            <div class="metric-card">
                <h4>üìù Variables Categ√≥ricas ({len(cat_cols)})</h4>
                <p>{', '.join(cat_cols[:5])}{'...' if len(cat_cols) > 5 else ''}</p>
            </div>
            """, unsafe_allow_html=True)

    with tab3:
        y_counts = y_raw.iloc[:, 0].astype(str).value_counts()
        col1, col2 = st.columns(2)

        with col1:
            fig = px.pie(
                values=y_counts.values,
                names=y_counts.index,
                title="Distribuci√≥n de Clases"
            )
            st.plotly_chart(fig, use_container_width=True)

        with col2:
            freq_df = pd.DataFrame({
                'Clase': y_counts.index,
                'Cantidad': y_counts.values,
                'Porcentaje': (y_counts.values / y_counts.sum() * 100).round(2)
            })
            st.dataframe(freq_df)

    with tab4:
        missing_counts = X_raw.isna().sum().sort_values(ascending=False)
        missing_data = missing_counts[missing_counts > 0]
        if len(missing_data) > 0:
            st.dataframe(missing_data)
        else:
            st.success("‚úÖ No hay valores faltantes")

def section_preprocessing():
    """Data preprocessing section"""
    st.header("üîß Preprocesamiento de Datos")

    ml_libs = get_ml_libs()
    if ml_libs is None:
        return

    if 'X_raw' not in st.session_state:
        st.warning("‚ö†Ô∏è Primero carga los datos.")
        return

    X_raw = st.session_state['X_raw']
    y_raw = st.session_state['y_raw']

    st.subheader("Configuraci√≥n de Preprocesamiento")

    col1, col2 = st.columns(2)

    with col1:
        # Variables to remove
        id_like_cols = [col for col in X_raw.columns
                       if any(keyword in col.lower()
                             for keyword in ['id', 'encounter', 'patient', 'diag_', 'payer', 'specialty'])]

        vars_to_remove = st.multiselect(
            "Variables a eliminar:",
            options=X_raw.columns.tolist(),
            default=id_like_cols
        )

        # Missing value threshold
        missing_threshold = st.slider("Umbral de valores faltantes (%)", 0, 50, 20) / 100

    with col2:
        # PCA threshold (se usar√° en la secci√≥n PCA)
        pca_threshold = st.slider("Varianza explicada PCA (%)", 80, 99, 95) / 100
        st.session_state['pca_threshold'] = pca_threshold

        # Show preprocessing steps
        st.markdown("""
        **Pasos del preprocesamiento:**
        1. Eliminar variables seleccionadas
        2. Eliminar variables con muchos faltantes
        3. Imputar valores faltantes
        4. Codificar variables categ√≥ricas
        5. Escalar variables num√©ricas
        6. Codificar variable objetivo
        """)

    if st.button("üöÄ Ejecutar Preprocesamiento", type="primary"):
        with st.spinner("Ejecutando preprocesamiento..."):
            # Step 1: Remove selected variables
            X_clean = X_raw.drop(columns=vars_to_remove, errors='ignore')

            # Step 2: Remove variables with too many missing values
            missing_prop = X_clean.isna().mean()
            cols_to_keep = missing_prop[missing_prop <= missing_threshold].index
            X_clean = X_clean[cols_to_keep]

            # Step 3: Separate numeric and categorical
            numeric_cols = X_clean.select_dtypes(include=[np.number]).columns.tolist()
            categorical_cols = X_clean.select_dtypes(include=['object', 'category']).columns.tolist()

            # Step 4: Handle missing values
            if len(numeric_cols) > 0:
                imputer_num = ml_libs['SimpleImputer'](strategy='median')
                X_num = pd.DataFrame(
                    imputer_num.fit_transform(X_clean[numeric_cols]),
                    columns=numeric_cols,
                    index=X_clean.index
                )
            else:
                X_num = pd.DataFrame(index=X_clean.index)

            if len(categorical_cols) > 0:
                imputer_cat = ml_libs['SimpleImputer'](strategy='most_frequent')
                X_cat = pd.DataFrame(
                    imputer_cat.fit_transform(X_clean[categorical_cols]),
                    columns=categorical_cols,
                    index=X_clean.index
                )

                # One-hot encoding for categorical variables
                X_cat_dummies = pd.get_dummies(X_cat, prefix_sep='=', drop_first=True)
            else:
                X_cat = pd.DataFrame(index=X_clean.index)
                X_cat_dummies = pd.DataFrame(index=X_clean.index)

            # Step 5: Scale numeric variables
            if len(numeric_cols) > 0:
                scaler = ml_libs['StandardScaler']()
                X_num_scaled = pd.DataFrame(
                    scaler.fit_transform(X_num),
                    columns=numeric_cols,
                    index=X_num.index
                )
            else:
                X_num_scaled = pd.DataFrame(index=X_clean.index)
                scaler = None

            # Step 6: Encode target variable
            label_encoder = ml_libs['LabelEncoder']()
            y_encoded = label_encoder.fit_transform(y_raw.iloc[:, 0])

            # Combine features for later PCA / modeling convenience
            X_all = pd.concat([X_num_scaled, X_cat_dummies.fillna(0)], axis=1)

            # Save processed data
            st.session_state.update({
                'X_num_scaled': X_num_scaled,
                'X_cat_processed': X_cat,
                'X_cat_dummies': X_cat_dummies,
                'X_all': X_all,
                'y_encoded': y_encoded,
                'label_encoder': label_encoder,
                'scaler': scaler,
                'numeric_cols': numeric_cols,
                'categorical_cols': categorical_cols
            })

        st.success("‚úÖ Preprocesamiento completado!")

        # Show results
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric("Variables Num√©ricas", len(numeric_cols))

        with col2:
            st.metric("Variables Categ√≥ricas", len(categorical_cols))

        with col3:
            st.metric("Variables Finales", X_num_scaled.shape[1] + X_cat_dummies.shape[1])

        with col4:
            st.metric("Muestras", len(X_clean))

        # Show class distribution
        st.subheader("Distribuci√≥n de clases procesadas")
        class_counts = pd.Series(y_encoded).map(
            lambda x: label_encoder.classes_[x]
        ).value_counts()

        fig = px.bar(
            x=class_counts.index,
            y=class_counts.values,
            title="Distribuci√≥n de Clases"
        )
        st.plotly_chart(fig, use_container_width=True)

def section_pca_exploratory():
    """Exploratory PCA on processed features"""
    st.header("üß≠ Exploraci√≥n Dimensional (PCA)")
    ml_libs = get_ml_libs()
    if ml_libs is None:
        return

    if not all(k in st.session_state for k in ['X_all', 'y_encoded', 'label_encoder']):
        st.warning("‚ö†Ô∏è Primero ejecuta el preprocesamiento.")
        return

    X_all = st.session_state['X_all']
    y_encoded = st.session_state['y_encoded']
    label_encoder = st.session_state['label_encoder']
    pca_threshold = st.session_state.get('pca_threshold', 0.95)

    max_components = int(min(50, max(2, X_all.shape[1])))
    pca = ml_libs['PCA'](n_components=max_components, random_state=RANDOM_STATE)
    pcs = pca.fit_transform(X_all)
    explained = np.cumsum(pca.explained_variance_ratio_)
    k = int(np.argmax(explained >= pca_threshold) + 1) if any(explained >= pca_threshold) else max_components

    st.markdown(f"**Componentes para alcanzar {int(pca_threshold*100)}% de varianza:** {k}")

    # Varianza acumulada
    fig_var = go.Figure()
    fig_var.add_trace(go.Scatter(y=explained, mode='lines+markers', name='Varianza acumulada'))
    fig_var.add_hline(y=pca_threshold, line_dash="dash", annotation_text=f"Umbral {int(pca_threshold*100)}%")
    fig_var.update_layout(title="Varianza Acumulada (PCA)", xaxis_title="Componentes", yaxis_title="Proporci√≥n")
    st.plotly_chart(fig_var, use_container_width=True)

    # PC1 vs PC2
    df_pca = pd.DataFrame({
        'PC1': pcs[:, 0],
        'PC2': pcs[:, 1],
        'Clase': label_encoder.inverse_transform(y_encoded)
    })
    fig_scatter = px.scatter(df_pca, x='PC1', y='PC2', color='Clase', title="PC1 vs PC2")
    st.plotly_chart(fig_scatter, use_container_width=True)

def section_feature_selection():
    """Feature selection section"""
    st.header("üìâ Selecci√≥n de Caracter√≠sticas")

    ml_libs = get_ml_libs()
    if ml_libs is None:
        return

    required_keys = ['X_num_scaled', 'X_cat_dummies', 'y_encoded', 'label_encoder']
    if not all(key in st.session_state for key in required_keys):
        st.warning("‚ö†Ô∏è Primero ejecuta el preprocesamiento.")
        return

    X_num_scaled = st.session_state['X_num_scaled']
    X_cat_dummies = st.session_state['X_cat_dummies']
    y_encoded = st.session_state['y_encoded']

    st.subheader("M√©todos de Selecci√≥n")

    methods = st.multiselect(
        "Selecciona m√©todos:",
        ["Chi-cuadrado (Categ√≥ricas)", "ANOVA F (Num√©ricas)", "Random Forest (Embedded)"],
        default=["Random Forest (Embedded)"]
    )

    # Feature selection parameters
    col1, col2 = st.columns(2)
    with col1:
        k_best_num = st.slider("N√∫mero de mejores caracter√≠sticas num√©ricas", 5, 50, 10)
    with col2:
        k_best_cat = st.slider("N√∫mero de mejores caracter√≠sticas categ√≥ricas", 5, 50, 10)

    if st.button("üîç Ejecutar Selecci√≥n", type="primary"):
        results = {}

        with st.spinner("Seleccionando caracter√≠sticas..."):

            # Method 1: Chi-squared for categorical
            if "Chi-cuadrado (Categ√≥ricas)" in methods and X_cat_dummies.shape[1] > 0:
                selector_chi2 = ml_libs['SelectKBest'](ml_libs['chi2'], k=min(k_best_cat, X_cat_dummies.shape[1]))
                X_cat_selected = selector_chi2.fit_transform(X_cat_dummies.fillna(0), y_encoded)
                selected_cat_features = X_cat_dummies.columns[selector_chi2.get_support()].tolist()

                results['chi2'] = {
                    'method': 'Chi-cuadrado',
                    'selected_vars': selected_cat_features,
                    'scores': pd.Series(selector_chi2.scores_, index=X_cat_dummies.columns).sort_values(ascending=False)
                }

            # Method 2: ANOVA F for numerical
            if "ANOVA F (Num√©ricas)" in methods and X_num_scaled.shape[1] > 0:
                selector_anova = ml_libs['SelectKBest'](ml_libs['f_classif'], k=min(k_best_num, X_num_scaled.shape[1]))
                X_num_selected = selector_anova.fit_transform(X_num_scaled, y_encoded)
                selected_num_features = X_num_scaled.columns[selector_anova.get_support()].tolist()

                results['anova'] = {
                    'method': 'ANOVA F',
                    'selected_vars': selected_num_features,
                    'scores': pd.Series(selector_anova.scores_, index=X_num_scaled.columns).sort_values(ascending=False)
                }

            # Method 3: Random Forest feature importance
            if "Random Forest (Embedded)" in methods:
                X_combined = pd.concat([X_num_scaled, X_cat_dummies.fillna(0)], axis=1)

                rf = ml_libs['RandomForestClassifier'](n_estimators=200, random_state=RANDOM_STATE, n_jobs=-1)
                rf.fit(X_combined, y_encoded)

                feature_importance = pd.Series(rf.feature_importances_, index=X_combined.columns)
                top_k = min(20, len(feature_importance))
                selected_rf_features = feature_importance.nlargest(top_k).index.tolist()

                results['random_forest'] = {
                    'method': 'Random Forest',
                    'selected_vars': selected_rf_features,
                    'scores': feature_importance.sort_values(ascending=False)
                }

        st.session_state['feature_selection_results'] = results
        st.success("‚úÖ Selecci√≥n de caracter√≠sticas completada!")

        # Show results
        for method_key, result in results.items():
            st.subheader(f"Resultados - {result['method']}")

            col1, col2 = st.columns(2)

            with col1:
                top_features = result['scores'].head(10)
                fig = px.bar(
                    x=top_features.values,
                    y=top_features.index,
                    orientation='h',
                    title=f"Top 10 - {result['method']}"
                )
                fig.update_layout(yaxis={'categoryorder':'total ascending'})
                st.plotly_chart(fig, use_container_width=True)

            with col2:
                st.markdown(f"""
                <div class="success-card">
                    <h4>üìä Resumen</h4>
                    <p><strong>Variables seleccionadas:</strong> {len(result['selected_vars'])}</p>
                    <p><strong>M√©todo:</strong> {result['method']}</p>
                </div>
                """, unsafe_allow_html=True)

                # Show selected features
                st.write("**Variables seleccionadas:**")
                for i, var in enumerate(result['selected_vars'][:10], 1):
                    st.write(f"{i}. {var}")
                if len(result['selected_vars']) > 10:
                    st.write(f"... y {len(result['selected_vars']) - 10} m√°s")

def _plot_roc_generic(y_test, y_proba, label_encoder, ml_libs):
    """Devuelve figura ROC y AUC (binaria o multiclase)"""
    n_classes = len(label_encoder.classes_)
    fig = go.Figure()
    roc_auc_display = None

    if y_proba is None:
        return None, None

    if n_classes == 2:
        fpr, tpr, _ = ml_libs['roc_curve'](y_test, y_proba[:, 1])
        roc_auc = ml_libs['auc'](fpr, tpr)
        fig.add_trace(go.Scatter(x=fpr, y=tpr, mode='lines', name=f'ROC (AUC={roc_auc:.3f})'))
        fig.add_trace(go.Scatter(x=[0,1], y=[0,1], mode='lines', name='Azar', line=dict(dash='dash')))
        fig.update_layout(title="Curva ROC (binaria)", xaxis_title="FPR", yaxis_title="TPR")
        roc_auc_display = roc_auc
    else:
        # One-vs-rest
        Y_bin = ml_libs['label_binarize'](y_test, classes=np.arange(n_classes))
        aucs = []
        max_curves = min(n_classes, 5)  # limitar curvas en la gr√°fica
        for i in range(n_classes):
            fpr, tpr, _ = ml_libs['roc_curve'](Y_bin[:, i], y_proba[:, i])
            roc_auc = ml_libs['auc'](fpr, tpr)
            aucs.append(roc_auc)
            if i < max_curves:
                fig.add_trace(go.Scatter(x=fpr, y=tpr, mode='lines', name=f'Clase {label_encoder.classes_[i]} (AUC={roc_auc:.3f})'))
        macro_auc = float(np.mean(aucs))
        fig.add_trace(go.Scatter(x=[0,1], y=[0,1], mode='lines', name='Azar', line=dict(dash='dash')))
        fig.update_layout(title=f"Curvas ROC (multiclase) ‚Ä¢ Macro-AUC={macro_auc:.3f}", xaxis_title="FPR", yaxis_title="TPR")
        roc_auc_display = macro_auc

    return fig, roc_auc_display

def _show_feature_importance(model, feature_names):
    """Grafica importancia si el modelo la expone"""
    if hasattr(model, "feature_importances_"):
        imp = pd.Series(model.feature_importances_, index=feature_names).sort_values(ascending=False).head(20)
        fig = px.bar(x=imp.values, y=imp.index, orientation='h', title="Importancia de caracter√≠sticas (Top 20)")
        fig.update_layout(yaxis={'categoryorder':'total ascending'})
        st.plotly_chart(fig, use_container_width=True)
    elif hasattr(model, "coef_"):
        try:
            coef = model.coef_
            if coef.ndim == 1:
                s = pd.Series(coef, index=feature_names).abs().sort_values(ascending=False).head(20)
            else:
                s = pd.Series(np.mean(np.abs(coef), axis=0), index=feature_names).sort_values(ascending=False).head(20)
            fig = px.bar(x=s.values, y=s.index, orientation='h', title="Coeficientes (magnitud, Top 20)")
            fig.update_layout(yaxis={'categoryorder':'total ascending'})
            st.plotly_chart(fig, use_container_width=True)
        except Exception:
            st.info("‚ÑπÔ∏è Este modelo no expone importancia de variables de forma directa.")

def section_individual_modeling():
    """Individual model training section"""
    st.header("ü§ñ Modelado Individual")

    ml_libs = get_ml_libs()
    if ml_libs is None:
        return

    # Check dependencies
    required_keys = ['X_num_scaled', 'X_cat_dummies', 'y_encoded', 'label_encoder']
    if not all(key in st.session_state for key in required_keys):
        st.warning("‚ö†Ô∏è Primero ejecuta preprocesamiento.")
        return

    if 'feature_selection_results' not in st.session_state:
        st.warning("‚ö†Ô∏è Primero ejecuta selecci√≥n de caracter√≠sticas.")
        return

    X_num_scaled = st.session_state['X_num_scaled']
    X_cat_dummies = st.session_state['X_cat_dummies']
    y_encoded = st.session_state['y_encoded']
    label_encoder = st.session_state['label_encoder']

    st.subheader("Configuraci√≥n del Modelo")

    col1, col2 = st.columns(2)

    with col1:
        # Feature selection method
        feature_method = st.selectbox(
            "M√©todo de selecci√≥n de caracter√≠sticas:",
            list(st.session_state['feature_selection_results'].keys())
        )

        # Model selection
        models_available = {
            "Random Forest": ml_libs['RandomForestClassifier'](random_state=RANDOM_STATE, n_jobs=-1),
            "Extra Trees": ml_libs['ExtraTreesClassifier'](random_state=RANDOM_STATE, n_jobs=-1),
            "Gradient Boosting": ml_libs['HistGradientBoostingClassifier'](random_state=RANDOM_STATE),
            "Logistic Regression": ml_libs['LogisticRegression'](random_state=RANDOM_STATE, max_iter=2000, n_jobs=-1),
            "SVM Linear": ml_libs['SVC'](kernel='linear', random_state=RANDOM_STATE, probability=True, max_iter=5000)
        }

        selected_model = st.selectbox("Modelo:", list(models_available.keys()))

    with col2:
        # Training parameters
        test_size = st.slider("Tama√±o del conjunto de prueba (%)", 10, 40, 25) / 100

        # Class balancing
        balancing_method = st.selectbox(
            "M√©todo de balanceo:",
            ["Ninguno", "Class Weight Balanced", "SMOTE"]
        )

    if st.button("üöÄ Entrenar Modelo", type="primary"):
        with st.spinner(f"Entrenando {selected_model}..."):
            # Prepare data
            selected_features = st.session_state['feature_selection_results'][feature_method]['selected_vars']

            # Combine features based on selection method
            if feature_method == 'chi2':
                X_final = X_cat_dummies[selected_features].fillna(0)
            elif feature_method == 'anova':
                X_final = X_num_scaled[selected_features]
            else:  # random_forest
                X_combined = pd.concat([X_num_scaled, X_cat_dummies.fillna(0)], axis=1)
                X_final = X_combined[selected_features]

            # Train-test split
            X_train, X_test, y_train, y_test = ml_libs['train_test_split'](
                X_final, y_encoded,
                test_size=test_size,
                stratify=y_encoded,
                random_state=RANDOM_STATE
            )

            # Prepare model
            model = models_available[selected_model]

            # Apply class balancing
            if balancing_method == "Class Weight Balanced" and hasattr(model, 'class_weight'):
                try:
                    model.set_params(class_weight='balanced')
                except Exception:
                    pass

            # Train model
            start_time = time.time()

            if balancing_method == "SMOTE" and ml_libs.get('IMBALANCED_AVAILABLE', False):
                try:
                    smote = ml_libs['SMOTE'](random_state=RANDOM_STATE)
                    X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)
                    model.fit(X_train_balanced, y_train_balanced)
                    st.info("‚úÖ SMOTE aplicado")
                except Exception as e:
                    model.fit(X_train, y_train)
                    st.warning(f"‚ö†Ô∏è SMOTE no disponible/compatible ({e}). Se entrena sin SMOTE.")
            else:
                model.fit(X_train, y_train)

            training_time = time.time() - start_time

            # Predictions
            y_pred = model.predict(X_test)
            y_pred_proba = model.predict_proba(X_test) if hasattr(model, 'predict_proba') else None

            # Metrics
            accuracy = ml_libs['accuracy_score'](y_test, y_pred)
            f1 = ml_libs['f1_score'](y_test, y_pred, average='macro')

            # Save results
            st.session_state['individual_results'] = {
                'model': model,
                'model_name': selected_model,
                'X_train': X_train,
                'X_test': X_test,
                'y_train': y_train,
                'y_test': y_test,
                'y_pred': y_pred,
                'y_pred_proba': y_pred_proba,
                'accuracy': accuracy,
                'f1_score': f1,
                'training_time': training_time,
                'selected_features': selected_features,
                'feature_method': feature_method,
                'balancing_method': balancing_method,
                'feature_names': X_final.columns.tolist()
            }

        st.success(f"‚úÖ Modelo {selected_model} entrenado!")

        # Show metrics
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Accuracy", f"{accuracy:.3f}")
        with col2:
            st.metric("F1 (macro)", f"{f1:.3f}")
        with col3:
            st.metric("Clases", len(st.session_state['label_encoder'].classes_))
        with col4:
            st.metric("Tiempo de entrenamiento (s)", f"{training_time:.2f}")

        # Detailed outputs
        res = st.session_state['individual_results']
        y_test = res['y_test']
        y_pred = res['y_pred']
        y_proba = res['y_pred_proba']
        classes_names = st.session_state['label_encoder'].classes_

        tab1, tab2, tab3, tab4 = st.tabs(["Matriz de Confusi√≥n", "ROC", "Reporte de Clasificaci√≥n", "Importancia de Variables"])

        with tab1:
            cm = ml_libs['confusion_matrix'](y_test, y_pred)
            fig_cm = plot_confusion_matrix(cm, classes_names)
            st.plotly_chart(fig_cm, use_container_width=True)

        with tab2:
            if y_proba is not None:
                fig_roc, roc_auc_val = _plot_roc_generic(y_test, y_proba, st.session_state['label_encoder'], ml_libs)
                if fig_roc is not None:
                    st.plotly_chart(fig_roc, use_container_width=True)
                    st.info(f"AUC: {roc_auc_val:.3f}")
            else:
                st.warning("El modelo no expone probabilidades (predict_proba).")

        with tab3:
            report_dict = ml_libs['classification_report'](y_test, y_pred, target_names=classes_names, output_dict=True)
            report_df = pd.DataFrame(report_dict).T.round(3)
            st.dataframe(report_df)

        with tab4:
            _show_feature_importance(res['model'], res['feature_names'])

def section_model_comparison():
    """Train and compare multiple models on the same split"""
    st.header("üî¨ Comparar Modelos")
    ml_libs = get_ml_libs()
    if ml_libs is None:
        return

    req = ['X_num_scaled', 'X_cat_dummies', 'y_encoded', 'label_encoder', 'feature_selection_results']
    if not all(k in st.session_state for k in req):
        st.warning("‚ö†Ô∏è Ejecuta preprocesamiento y selecci√≥n de caracter√≠sticas primero.")
        return

    X_num_scaled = st.session_state['X_num_scaled']
    X_cat_dummies = st.session_state['X_cat_dummies']
    y_encoded = st.session_state['y_encoded']
    label_encoder = st.session_state['label_encoder']

    st.subheader("Configuraci√≥n")
    col1, col2 = st.columns(2)

    with col1:
        feature_method = st.selectbox(
            "M√©todo de selecci√≥n de caracter√≠sticas:",
            list(st.session_state['feature_selection_results'].keys()),
            key="cmp_feature_method"
        )
        test_size = st.slider("Tama√±o del conjunto de prueba (%)", 10, 40, 25, key="cmp_test_size") / 100

    with col2:
        balancing_method = st.selectbox(
            "M√©todo de balanceo:",
            ["Ninguno", "Class Weight Balanced", "SMOTE"],
            key="cmp_balancing"
        )
        models_to_run = st.multiselect(
            "Modelos a comparar:",
            ["Random Forest", "Extra Trees", "Gradient Boosting", "Logistic Regression", "SVM Linear"],
            default=["Random Forest", "Extra Trees", "Gradient Boosting", "Logistic Regression"]
        )

    if st.button("üèéÔ∏è Ejecutar comparaci√≥n", type="primary"):
        with st.spinner("Entrenando y evaluando modelos..."):
            # Features
            selected_features = st.session_state['feature_selection_results'][feature_method]['selected_vars']
            if feature_method == 'chi2':
                X_final = X_cat_dummies[selected_features].fillna(0)
            elif feature_method == 'anova':
                X_final = X_num_scaled[selected_features]
            else:
                X_combined = pd.concat([X_num_scaled, X_cat_dummies.fillna(0)], axis=1)
                X_final = X_combined[selected_features]

            X_train, X_test, y_train, y_test = ml_libs['train_test_split'](
                X_final, y_encoded, test_size=test_size, stratify=y_encoded, random_state=RANDOM_STATE
            )

            base_models = {
                "Random Forest": ml_libs['RandomForestClassifier'](random_state=RANDOM_STATE, n_jobs=-1),
                "Extra Trees": ml_libs['ExtraTreesClassifier'](random_state=RANDOM_STATE, n_jobs=-1),
                "Gradient Boosting": ml_libs['HistGradientBoostingClassifier'](random_state=RANDOM_STATE),
                "Logistic Regression": ml_libs['LogisticRegression'](random_state=RANDOM_STATE, max_iter=2000, n_jobs=-1),
                "SVM Linear": ml_libs['SVC'](kernel='linear', random_state=RANDOM_STATE, probability=True, max_iter=5000)
            }

            results = []
            details = {}
            for name in models_to_run:
                model = base_models[name]
                # Balanceo
                if balancing_method == "Class Weight Balanced" and hasattr(model, 'class_weight'):
                    try:
                        model.set_params(class_weight='balanced')
                    except Exception:
                        pass

                start = time.time()
                if balancing_method == "SMOTE" and ml_libs.get('IMBALANCED_AVAILABLE', False):
                    try:
                        smote = ml_libs['SMOTE'](random_state=RANDOM_STATE)
                        X_tr, y_tr = smote.fit_resample(X_train, y_train)
                        model.fit(X_tr, y_tr)
                        smote_used = True
                    except Exception:
                        model.fit(X_train, y_train)
                        smote_used = False
                else:
                    model.fit(X_train, y_train)
                    smote_used = False
                ttrain = time.time() - start

                y_pred = model.predict(X_test)
                y_proba = model.predict_proba(X_test) if hasattr(model, 'predict_proba') else None
                acc = ml_libs['accuracy_score'](y_test, y_pred)
                f1 = ml_libs['f1_score'](y_test, y_pred, average='macro')

                auc_val = None
                if y_proba is not None:
                    _, auc_val = _plot_roc_generic(y_test, y_proba, label_encoder, ml_libs)

                results.append({
                    'Modelo': name,
                    'Accuracy': round(acc, 4),
                    'F1_macro': round(f1, 4),
                    'AUC_macro': round(auc_val, 4) if auc_val is not None else None,
                    'Tiempo_s': round(ttrain, 2),
                    'SMOTE': smote_used
                })

                details[name] = {
                    'model': model,
                    'y_pred': y_pred,
                    'y_proba': y_proba,
                    'cm': ml_libs['confusion_matrix'](y_test, y_pred)
                }

            df_results = pd.DataFrame(results).sort_values(by=['F1_macro','Accuracy'], ascending=False)
            st.session_state['comparison_results'] = {
                'table': df_results,
                'details': details,
                'X_test': X_test,
                'y_test': y_test,
                'feature_names': X_final.columns.tolist()
            }

        st.success("‚úÖ Comparaci√≥n completa")

        # Mostrar tabla y gr√°fico
        df_results = st.session_state['comparison_results']['table']
        st.subheader("Resultados comparativos")
        st.dataframe(df_results, use_container_width=True)

        fig_bar = px.bar(df_results, x='Modelo', y='F1_macro', title='F1 (macro) por modelo')
        st.plotly_chart(fig_bar, use_container_width=True)

        # Detalles por modelo
        st.subheader("üîé Detalles de un modelo")
        model_to_inspect = st.selectbox("Selecciona un modelo", df_results['Modelo'].tolist())
        det = st.session_state['comparison_results']['details'][model_to_inspect]
        classes_names = label_encoder.classes_
        cm_fig = plot_confusion_matrix(det['cm'], classes_names)
        st.plotly_chart(cm_fig, use_container_width=True)

        if det['y_proba'] is not None:
            fig_roc, auc_val = _plot_roc_generic(
                st.session_state['comparison_results']['y_test'],
                det['y_proba'],
                label_encoder, ml_libs
            )
            st.plotly_chart(fig_roc, use_container_width=True)
            st.info(f"AUC: {auc_val:.3f}")
        else:
            st.warning("Este modelo no expone probabilidades.")

def section_help():
    st.header("‚ùì Ayuda")
    st.markdown("""
**¬øQu√© hace esta app?**
- Carga datos (UCI o CSV) y explora el dataset.
- Preprocesa: limpieza, imputaci√≥n, codificaci√≥n, escalado.
- Hace **PCA exploratorio** para entender la estructura de los datos.
- Selecciona caracter√≠sticas (Chi¬≤, ANOVA, Random Forest embedded).
- Entrena un **modelo individual** con m√©tricas, ROC y matriz de confusi√≥n.
- Permite **comparar varios modelos** en el mismo split y ver sus detalles.

**Consejos**
- Si tu objetivo es binario, la curva ROC y AUC ser√°n m√°s claras.
- En datos desbalanceados, prueba `Class Weight Balanced` o `SMOTE`.
- No todos los modelos exponen `predict_proba`; en esos casos no habr√° ROC.
- Mant√©n el n√∫mero de variables razonable para evitar sobreajuste.

**Requisitos**
- `scikit-learn`, `plotly`, `pandas`, `numpy`, `streamlit`.
- Opcional: `imbalanced-learn` para SMOTE y `ucimlrepo` para bajar el dataset UCI.
    """)

# ======== MAIN APP NAV ========
def main():
    st.title("ü©∫ An√°lisis de Diabetes - ML Pipeline")
    with st.sidebar:
        st.header("Navegaci√≥n")
        page = st.radio("Ir a:", [
            "Carga y Exploraci√≥n",
            "Preprocesamiento",
            "PCA Exploratorio",
            "Selecci√≥n de Caracter√≠sticas",
            "Modelado Individual",
            "Comparar Modelos",
            "Ayuda"
        ])
        st.markdown("---")
        st.caption("v1.0 ‚Ä¢ Demo educativa")

    if page == "Carga y Exploraci√≥n":
        section_data_loading()
    elif page == "Preprocesamiento":
        section_preprocessing()
    elif page == "PCA Exploratorio":
        section_pca_exploratory()
    elif page == "Selecci√≥n de Caracter√≠sticas":
        section_feature_selection()
    elif page == "Modelado Individual":
        section_individual_modeling()
    elif page == "Comparar Modelos":
        section_model_comparison()
    else:
        section_help()

if __name__ == "__main__":
    main()